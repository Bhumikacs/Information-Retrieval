{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Practical 2\n",
        "\n",
        "Aim : Retrieval Models\n",
        "*   Implement the Boolean retrieval model and process queries.\n",
        "*   Implement the vector space model with TF-IDF weighting and cosine similarity."
      ],
      "metadata": {
        "id": "Hy5_vXhK-RUH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A. Implement the Boolean retrieval model and process queries."
      ],
      "metadata": {
        "id": "qRQY6MDs-GZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"T114 | Bhumika Shelar\")\n",
        "\n",
        "# Import stopwords\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop = set(stopwords.words('english'))\n",
        "\n",
        "# Documents\n",
        "docs = {\n",
        "    1: \"apple banana orange\",\n",
        "    2: \"apple banana\",\n",
        "    3: \"banana orange\",\n",
        "    4: \"apple\"\n",
        "}\n",
        "\n",
        "# Build inverted index (stopwords removed)\n",
        "def build_index(docs):\n",
        "    index = {}\n",
        "    for doc_id, text in docs.items():\n",
        "        for term in text.lower().split():\n",
        "            if term not in stop:                         # remove stopwords\n",
        "                index.setdefault(term, set()).add(doc_id)\n",
        "    return index\n",
        "\n",
        "# Boolean operations\n",
        "def boolean_and(terms, index):\n",
        "    result = index.get(terms[0], set())\n",
        "    for t in terms[1:]: result &= index.get(t, set())\n",
        "    return list(result)\n",
        "\n",
        "def boolean_or(terms, index):\n",
        "    result = set()\n",
        "    for t in terms: result |= index.get(t, set())\n",
        "    return list(result)\n",
        "\n",
        "def boolean_not(term, index, total_docs):\n",
        "    return list(set(range(1, total_docs+1)) - index.get(term, set()))\n",
        "\n",
        "# Build index\n",
        "inv_index = build_index(docs)\n",
        "\n",
        "# Queries\n",
        "print(\"Documents containing 'apple' AND 'banana':\", boolean_and([\"apple\",\"banana\"], inv_index))\n",
        "print(\"Documents containing 'apple' OR 'orange':\", boolean_or([\"apple\",\"orange\"], inv_index))\n",
        "print(\"Documents NOT containing 'orange':\", boolean_not(\"orange\", inv_index, len(docs)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b7Z8iNZ-LIG",
        "outputId": "3e63c9c0-00d3-4f41-f480-25a492b1643f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T114 | Bhumika Shelar\n",
            "Documents containing 'apple' AND 'banana': [1, 2]\n",
            "Documents containing 'apple' OR 'orange': [1, 2, 3]\n",
            "Documents NOT containing 'orange': [2, 4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "B. Implement the vector space model with TF-IDF weighting and cosine\n",
        "similarity"
      ],
      "metadata": {
        "id": "DX719ALP-BLg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGA480FY5dqw",
        "outputId": "c3eba38c-b067-4bd5-8935-56f11be6b87a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T114 | Bhumika Shelar\n",
            "Fit Vectorizer to train set [[1 0 1 0]\n",
            " [0 1 0 1]]\n",
            "Transform Vectorizer to test set [[0 1 1 1]]\n",
            "[1 0 1 0]\n",
            "[0 1 0 1]\n",
            "[0 1 1 1]\n",
            "0.816\n",
            "\n",
            "[[0.70710678 0.         0.70710678 0.        ]\n",
            " [0.         0.70710678 0.         0.70710678]]\n",
            "\n",
            "[[0.         0.57735027 0.57735027 0.57735027]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "print(\"T114 | Bhumika Shelar\")\n",
        "# Import libraries\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "\n",
        "# Training and test documents\n",
        "train_set = [\"The sky is blue.\", \"The sun is bright.\"]\n",
        "test_set = [\"The sun in the sky is bright.\"]\n",
        "\n",
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "stopWords = stopwords.words('english')\n",
        "\n",
        "# Create CountVectorizer and TfidfTransformer\n",
        "vectorizer = CountVectorizer(stop_words=stopWords)\n",
        "transformer = TfidfTransformer()\n",
        "\n",
        "# Convert documents to Bag-of-Words (BoW)\n",
        "train_vec = vectorizer.fit_transform(train_set).toarray()\n",
        "test_vec = vectorizer.transform(test_set).toarray()\n",
        "\n",
        "# Display BoW vectors\n",
        "print(\"Fit Vectorizer to train set\", train_vec)\n",
        "print(\"Transform Vectorizer to test set\", test_vec)\n",
        "\n",
        "# Cosine similarity function\n",
        "cos_sim = lambda a, b: round(np.inner(a, b) / (norm(a) * norm(b)), 3)\n",
        "\n",
        "# Show train & test vectors and cosine similarity\n",
        "for v in train_vec:\n",
        "    print(v)\n",
        "\n",
        "for tv in test_vec:\n",
        "    print(tv)\n",
        "    print(cos_sim(v, tv))\n",
        "\n",
        "# TF-IDF for training set\n",
        "transformer.fit(train_vec)\n",
        "print()\n",
        "print(transformer.transform(train_vec).toarray())\n",
        "\n",
        "# TF-IDF for test set\n",
        "transformer.fit(test_vec)\n",
        "print()\n",
        "print(transformer.transform(test_vec).todense())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1**\n",
        "\n",
        "Implement the Boolean retrieval model for the following corpus.\n",
        "\n",
        "Document 1: 'this is the first document.'\n",
        "\n",
        "Document 2: 'this document is the second document.'\n",
        "\n",
        "Document 3: 'And this is the third one.'\n",
        "\n",
        "Document 4: 'Is this the first document?'\n",
        "\n",
        "Process the query “first and third”."
      ],
      "metadata": {
        "id": "VqGF_Ate7AGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"T114 | Bhumika Shelar\")\n",
        "# Documents\n",
        "docs = {\n",
        "    1: \"this is the first document\",\n",
        "    2: \"this document is the second document\",\n",
        "    3: \"and this is the third one\",\n",
        "    4: \"is this the first document\"\n",
        "}\n",
        "\n",
        "# Build inverted index\n",
        "index = {}\n",
        "for doc_id, text in docs.items():\n",
        "    for term in text.split():\n",
        "        index.setdefault(term, set()).add(doc_id)\n",
        "\n",
        "# Boolean AND\n",
        "def boolean_and(terms):\n",
        "    sets = [index.get(t, set()) for t in terms]\n",
        "    return list(set.intersection(*sets)) if sets else []\n",
        "\n",
        "# Query\n",
        "result = boolean_and([\"first\", \"third\"])\n",
        "\n",
        "print(\"Documents matching 'first AND third':\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-dcKrTF5lC5",
        "outputId": "0ae85353-94f0-43fd-895f-a72f099afbac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T114 | Bhumika Shelar\n",
            "Documents matching 'first AND third': []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2**\n",
        "\n",
        "Implement the Boolean retrieval model for the following corpus.\n",
        "\n",
        "Document 1:The cat chased the dog around the garden.\n",
        "\n",
        "Document2: She was sitting in the garden last night.\n",
        "\n",
        "Document 3: I read the book the night before.\n",
        "\n",
        "Process the query “garden or night”."
      ],
      "metadata": {
        "id": "N_uBO4u07c6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"T114 | Bhumika Shelar\")\n",
        "# Documents\n",
        "docs = {\n",
        "    1: \"The cat chased the dog around the garden\",\n",
        "    2: \"She was sitting in the garden last night\",\n",
        "    3: \"I read the book the night before\"\n",
        "}\n",
        "\n",
        "# Build inverted index\n",
        "index = {}\n",
        "for doc_id, text in docs.items():\n",
        "    for word in text.lower().split():\n",
        "        index.setdefault(word, set()).add(doc_id)\n",
        "\n",
        "# Boolean OR\n",
        "def boolean_or(terms):\n",
        "    return list(set().union(*(index.get(t, set()) for t in terms)))\n",
        "\n",
        "# Query\n",
        "result = boolean_or([\"garden\", \"night\"])\n",
        "\n",
        "print(\"Documents matching 'garden OR night':\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yj1v_ha47gWO",
        "outputId": "1adb3fba-3d66-4674-8e5a-e83bb2d93f16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T114 | Bhumika Shelar\n",
            "Documents matching 'garden OR night': [1, 2, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3**\n",
        "\n",
        "Implement the Boolean retrieval model for the following corpus\n",
        "\n",
        "Document 1:BSc lectures start at 7.\n",
        "\n",
        "Document 2:My lectures are over.\n",
        "\n",
        "Document 3: Today is a holiday.\n",
        "\n",
        "Process the query “not lectures”"
      ],
      "metadata": {
        "id": "4sqiv2oF7mJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"T114 | Bhumika Shelar\")\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop = set(stopwords.words('english'))\n",
        "\n",
        "# Documents\n",
        "docs = {\n",
        "    1: \"BSc lectures start at 7\",\n",
        "    2: \"My lectures are over\",\n",
        "    3: \"Today is a holiday\"\n",
        "}\n",
        "\n",
        "# Build inverted index without stopwords\n",
        "index = {}\n",
        "for doc_id, text in docs.items():\n",
        "    for word in text.lower().split():\n",
        "        if word not in stop:\n",
        "            index.setdefault(word, set()).add(doc_id)\n",
        "\n",
        "# Boolean NOT\n",
        "def boolean_not(term):\n",
        "    return list(set(docs.keys()) - index.get(term, set()))\n",
        "# Query\n",
        "result = boolean_not(\"lectures\")\n",
        "print(\"Documents matching 'NOT lectures':\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozqrwXk57rBm",
        "outputId": "fd7571ac-ec87-4deb-9dc4-7040d81be5b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T114 | Bhumika Shelar\n",
            "Documents matching 'NOT lectures': [3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4**\n",
        "\n",
        "Implement the vector space model with TF-IDF weighting for the\n",
        "following corpus\n",
        "\n",
        "Document 1: \"Document about python programming language and data\n",
        "analysis.\"\n",
        "\n",
        "Document 2: \"Document discussing machine learning algorithms and\n",
        "programming techniques.\"\n",
        "\n",
        "Document3: \"Overview of natural language processing and its\n",
        "applications.\"\n",
        "\n",
        "query = \"python programming\""
      ],
      "metadata": {
        "id": "p9r_2pud7w6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"T114 | Bhumika Shelar\")\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "\n",
        "# Documents\n",
        "docs = [\n",
        "    \"Document about python programming language and data analysis.\",\n",
        "    \"Document discussing machine learning algorithms and programming techniques.\",\n",
        "    \"Overview of natural language processing and its applications.\"\n",
        "]\n",
        "\n",
        "query = [\"python programming\"]\n",
        "\n",
        "# Bag-of-Words with Auto Stopword Removal\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "transformer = TfidfTransformer()\n",
        "\n",
        "# TF-IDF for documents\n",
        "doc_tfidf = transformer.fit_transform(vectorizer.fit_transform(docs)).toarray()\n",
        "\n",
        "# TF-IDF for query\n",
        "query_tfidf = transformer.transform(vectorizer.transform(query)).toarray()\n",
        "\n",
        "# Cosine similarity\n",
        "cos = lambda a, b: round(np.inner(a, b) / (norm(a) * norm(b)), 3)\n",
        "\n",
        "# Output\n",
        "print(\"TF-IDF for documents:\")\n",
        "print(doc_tfidf)\n",
        "\n",
        "print(\"\\nTF-IDF for query:\")\n",
        "print(query_tfidf)\n",
        "\n",
        "print(\"\\nCosine Similarity Scores:\")\n",
        "for i, vec in enumerate(doc_tfidf, 1):\n",
        "    print(f\"Document {i}: {cos(vec, query_tfidf[0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGAX3faG7xTv",
        "outputId": "638b31e2-638d-45b3-fa42-51adbea1cb6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T114 | Bhumika Shelar\n",
            "TF-IDF for documents:\n",
            "[[0.         0.45954803 0.         0.45954803 0.         0.34949812\n",
            "  0.34949812 0.         0.         0.         0.         0.\n",
            "  0.34949812 0.45954803 0.        ]\n",
            " [0.40301621 0.         0.         0.         0.40301621 0.30650422\n",
            "  0.         0.40301621 0.40301621 0.         0.         0.\n",
            "  0.30650422 0.         0.40301621]\n",
            " [0.         0.         0.46735098 0.         0.         0.\n",
            "  0.35543247 0.         0.         0.46735098 0.46735098 0.46735098\n",
            "  0.         0.         0.        ]]\n",
            "\n",
            "TF-IDF for query:\n",
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.60534851 0.79596054 0.        ]]\n",
            "\n",
            "Cosine Similarity Scores:\n",
            "Document 1: 0.577\n",
            "Document 2: 0.186\n",
            "Document 3: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 5**\n",
        "\n",
        "Implement the Boolean retrieval model for the following corpus\n",
        "\n",
        "Document 1:The university exam is scheduled next week.\n",
        "\n",
        "Document2: The university of mumbai has declared the result.\n",
        "\n",
        "Process the query “university and Mumbai”."
      ],
      "metadata": {
        "id": "Zoetp5_Q79y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"T114 | Bhumika Shelar\")\n",
        "# Stopwords list (short manual list for simplicity)\n",
        "stopwords = {\"the\", \"is\", \"has\", \"a\", \"of\", \"in\", \"at\", \"on\"}\n",
        "\n",
        "# Documents\n",
        "docs = {\n",
        "    1: \"The university exam is scheduled next week\",\n",
        "    2: \"The university of mumbai has declared the result\"\n",
        "}\n",
        "\n",
        "# Build inverted index (remove stopwords)\n",
        "def build_index(docs):\n",
        "    index = {}\n",
        "    for doc_id, text in docs.items():\n",
        "        for term in text.lower().split():\n",
        "            if term not in stopwords:        # remove stopwords\n",
        "                index.setdefault(term, set()).add(doc_id)\n",
        "    return index\n",
        "\n",
        "# Boolean AND operation\n",
        "def boolean_and(terms, index):\n",
        "    result = index.get(terms[0], set())\n",
        "    for term in terms[1:]:\n",
        "        result &= index.get(term, set())\n",
        "    return list(result)\n",
        "\n",
        "# Build index\n",
        "inverted_index = build_index(docs)\n",
        "\n",
        "# Query: remove stopwords automatically\n",
        "query = [t for t in [\"university\", \"mumbai\"] if t not in stopwords]\n",
        "\n",
        "# Process query\n",
        "result = boolean_and(query, inverted_index)\n",
        "print(\"Documents matching 'university AND mumbai':\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rShdS7eX7-OO",
        "outputId": "85e1e749-12ab-4ab2-c263-7f77ba7283ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T114 | Bhumika Shelar\n",
            "Documents matching 'university AND mumbai': [2]\n"
          ]
        }
      ]
    }
  ]
}