{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Practical 1**\n",
        "\n",
        "**Aim : Document Indexing and Retrieval**\n",
        "*   Implement an inverted index construction algorithm.\n",
        "*   Build a simple document retrieval system using the constructed index.\n"
      ],
      "metadata": {
        "id": "tYXNPpAA_xU8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChAGFS08_gus",
        "outputId": "ca47d6fc-915f-4bd0-e07f-70c7163cdf68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T114 | Bhumika Shelar\n",
            "Inverted index:\n",
            "\n",
            "quick -> Document 1 (1), \n",
            "sun -> Document 2 (1), \n",
            "brown -> Document 1 (1), \n",
            "slept -> Document 2 (1), \n",
            "dog -> Document 1 (1), Document 2 (1), \n",
            "lazy -> Document 1 (1), Document 2 (1), \n",
            "fox -> Document 1 (1), \n",
            "jumped -> Document 1 (1), \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "print(\"T114 | Bhumika Shelar\")\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#Define the documents\n",
        "document1= \"The quick brown fox jumped over the lazy dog\"\n",
        "document2=\"The lazy dog slept in the sun\"\n",
        "\n",
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "stopWords= stopwords.words('english')\n",
        "\n",
        "tokens1=document1.lower().split()\n",
        "tokens2=document2.lower().split()\n",
        "\n",
        "terms=list(set(tokens1+tokens2))\n",
        "\n",
        "inverted_index={}\n",
        "occ_num_doc1={}\n",
        "occ_num_doc2={}\n",
        "\n",
        "for term in terms:\n",
        "    if term in stopWords:\n",
        "        continue\n",
        "    documents=[]\n",
        "\n",
        "    if term in tokens1:\n",
        "        documents.append(\"Document 1\")\n",
        "        occ_num_doc1[term]=tokens1.count(term)\n",
        "\n",
        "    if term in tokens2:\n",
        "        documents.append(\"Document 2\")\n",
        "        occ_num_doc2[term]=tokens2.count(term)\n",
        "    inverted_index[term]=documents\n",
        "print(\"Inverted index:\\n\")\n",
        "\n",
        "for term,docs in inverted_index.items():\n",
        "    print(term, \"->\",end=\" \")\n",
        "\n",
        "    for doc in docs:\n",
        "        if doc ==\"Document 1\":\n",
        "            print(f\"{doc} ({occ_num_doc1.get(term,0)}),\", end=\" \")\n",
        "        else:\n",
        "            print(f\"{doc} ({occ_num_doc2.get(term,0)}),\", end=\" \")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1**\n",
        "\n",
        "Implement an inverted index construction algorithm for the following two documents.\n",
        "\n",
        "document1 = \"The computer science students are appearing for practical examination.\"\n",
        "\n",
        "document2 = \"computer science practical examination will start tomorrow.\"\n",
        "\n",
        "Build a simple document retrieval system using the constructed index to find the\n",
        "documents containing terms “computer science”."
      ],
      "metadata": {
        "id": "xXjL8q4d_9Ac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"T114 | Bhumika Shelar\")\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "document1 = \"The computer science students are appearing for practical examination.\"\n",
        "document2 = \"computer science practical examination will start tomorrow.\"\n",
        "nltk.download('stopwords')\n",
        "stopWords = stopwords.words('english')\n",
        "\n",
        "tokens1 = document1.lower().split()\n",
        "tokens2 = document2.lower().split()\n",
        "\n",
        "terms = list(set(tokens1 + tokens2))\n",
        "\n",
        "inverted_index = {}\n",
        "occ_num_doc1 = {}\n",
        "occ_num_doc2 = {}\n",
        "\n",
        "for term in terms:\n",
        "    if term in stopWords:\n",
        "        continue  # ignore stopwords\n",
        "    documents = []\n",
        "    if term in tokens1:\n",
        "        documents.append(\"Document 1\")\n",
        "        occ_num_doc1[term] = tokens1.count(term)\n",
        "\n",
        "    if term in tokens2:\n",
        "        documents.append(\"Document 2\")\n",
        "        occ_num_doc2[term] = tokens2.count(term)\n",
        "\n",
        "    inverted_index[term] = documents\n",
        "\n",
        "query = [\"computer\", \"science\"]   # query terms\n",
        "\n",
        "print(\"\\nDocuments containing the terms 'computer science':\\n\")\n",
        "result_docs = set(inverted_index.get(query[0], []))\n",
        "for term in query[1:]:\n",
        "    result_docs = result_docs.intersection(inverted_index.get(term, []))\n",
        "if result_docs:\n",
        "    print(\"Retrieved Documents:\", result_docs)\n",
        "else:\n",
        "    print(\"No document contains all query terms.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a7pLfMv_737",
        "outputId": "a853f7a0-fe65-4bc7-cc64-03942e833fe4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T114 | Bhumika Shelar\n",
            "\n",
            "Documents containing the terms 'computer science':\n",
            "\n",
            "Retrieved Documents: {'Document 2', 'Document 1'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2**\n",
        "\n",
        "Implement an inverted index construction algorithm for the following two documents.\n",
        "\n",
        "document1 = \"today is a beautiful and a sunny day\"\n",
        "\n",
        "document2 = \"it was a cloudy day\"\n",
        "\n",
        "Build a simple document retrieval system using the constructed index to find the\n",
        "documents containing terms “beautiful day”."
      ],
      "metadata": {
        "id": "a-n82HR4_9-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"T114 | Bhumika Shelar\")\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "document1 = \"today is a beautiful and a sunny day\"\n",
        "document2 = \"it was a cloudy day\"\n",
        "nltk.download('stopwords')\n",
        "stopWords = stopwords.words('english')\n",
        "\n",
        "tokens1 = document1.lower().split()\n",
        "tokens2 = document2.lower().split()\n",
        "\n",
        "# Unique list of terms\n",
        "terms = list(set(tokens1 + tokens2))\n",
        "\n",
        "# Inverted index and occurrences\n",
        "inverted_index = {}\n",
        "occ_num_doc1 = {}\n",
        "occ_num_doc2 = {}\n",
        "\n",
        "# Build inverted index\n",
        "for term in terms:\n",
        "    if term in stopWords:\n",
        "        continue  # ignore stopwords\n",
        "\n",
        "    documents = []\n",
        "    if term in tokens1:\n",
        "        documents.append(\"Document 1\")\n",
        "        occ_num_doc1[term] = tokens1.count(term)\n",
        "\n",
        "    if term in tokens2:\n",
        "        documents.append(\"Document 2\")\n",
        "        occ_num_doc2[term] = tokens2.count(term)\n",
        "    inverted_index[term] = documents\n",
        "query = [\"beautiful\", \"day\"]   # query terms\n",
        "print(\"\\nDocuments containing the terms 'beautiful day':\\n\")\n",
        "result_docs = set(inverted_index.get(query[0], []))\n",
        "for term in query[1:]:\n",
        "    result_docs = result_docs.intersection(inverted_index.get(term, []))\n",
        "if result_docs:\n",
        "    print(\"Retrieved Documents:\", result_docs)\n",
        "else:\n",
        "    print(\"No document contains all query terms.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUxwk5BaAAkl",
        "outputId": "bca23f55-faff-47c4-ec3e-e2bfa8b98c19"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T114 | Bhumika Shelar\n",
            "\n",
            "Documents containing the terms 'beautiful day':\n",
            "\n",
            "Retrieved Documents: {'Document 1'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3**\n",
        "\n",
        "Implement an inverted index construction algorithm for the following two documents\n",
        "\n",
        "document1 = \"The quick brown fox jumped over the lazy dog\"\n",
        "\n",
        "document2 = \"The lazy dog slept in the sun\"\n",
        "\n",
        "Build a simple document retrieval system using the constructed index to\n",
        "find the documents containing terms “lazy sun”"
      ],
      "metadata": {
        "id": "DEXTAg_8AA8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"T114 | Bhumika Shelar\")\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Define the documents\n",
        "document1 = \"The quick brown fox jumped over the lazy dog\"\n",
        "document2 = \"The lazy dog slept in the sun\"\n",
        "\n",
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "stopWords = stopwords.words('english')\n",
        "\n",
        "# Tokenize\n",
        "tokens1 = document1.lower().split()\n",
        "tokens2 = document2.lower().split()\n",
        "terms = list(set(tokens1 + tokens2))\n",
        "\n",
        "inverted_index = {}\n",
        "occ_num_doc1 = {}\n",
        "occ_num_doc2 = {}\n",
        "for term in terms:\n",
        "    if term in stopWords:\n",
        "        continue  # ignore stopwords\n",
        "    documents = []\n",
        "    if term in tokens1:\n",
        "        documents.append(\"Document 1\")\n",
        "        occ_num_doc1[term] = tokens1.count(term)\n",
        "\n",
        "    if term in tokens2:\n",
        "        documents.append(\"Document 2\")\n",
        "        occ_num_doc2[term] = tokens2.count(term)\n",
        "\n",
        "    inverted_index[term] = documents\n",
        "\n",
        "query = [\"lazy\", \"sun\"]   # query terms\n",
        "\n",
        "print(\"\\nDocuments containing the terms 'lazy sun':\\n\")\n",
        "result_docs = set(inverted_index.get(query[0], []))\n",
        "\n",
        "for term in query[1:]:\n",
        "    result_docs = result_docs.intersection(inverted_index.get(term, []))\n",
        "\n",
        "if result_docs:\n",
        "    print(\"Retrieved Documents:\", result_docs)\n",
        "else:\n",
        "    print(\"No document contains all query terms.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QBzvvwkAE9E",
        "outputId": "e28771a8-49d3-4601-922c-6c0c7bbe7c47"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T114 | Bhumika Shelar\n",
            "\n",
            "Documents containing the terms 'lazy sun':\n",
            "\n",
            "Retrieved Documents: {'Document 2'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4**\n",
        "\n",
        "Implement an inverted index construction algorithm for the following two documents\n",
        "\n",
        "document1 = \"best of luck tycs students for your practical examination.\"\n",
        "\n",
        "document2 = \"tycs students please carry your journal at the time of practical examination.\"\n",
        "\n",
        "Build a simple document retrieval system using the constructed index to find the documents containing terms “tycs journal”"
      ],
      "metadata": {
        "id": "cyZX2uPDAFWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"T114 | Bhumika Shelar\")\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "document1 = \"best of luck tycs students for your practical examination.\"\n",
        "document2 = \"tycs students please carry your journal at the time of practical examination.\"\n",
        "nltk.download('stopwords')\n",
        "stopWords = stopwords.words('english')\n",
        "\n",
        "tokens1 = document1.lower().split()\n",
        "tokens2 = document2.lower().split()\n",
        "\n",
        "terms = list(set(tokens1 + tokens2))\n",
        "inverted_index = {}\n",
        "occ_num_doc1 = {}\n",
        "occ_num_doc2 = {}\n",
        "for term in terms:\n",
        "    if term in stopWords:\n",
        "        continue  # ignore stopwords\n",
        "    documents = []\n",
        "    if term in tokens1:\n",
        "        documents.append(\"Document 1\")\n",
        "        occ_num_doc1[term] = tokens1.count(term)\n",
        "    if term in tokens2:\n",
        "        documents.append(\"Document 2\")\n",
        "        occ_num_doc2[term] = tokens2.count(term)\n",
        "\n",
        "    inverted_index[term] = documents\n",
        "query = [\"tycs\", \"journal\"]   # query terms\n",
        "print(\"\\nDocuments containing the terms 'tycs journal':\\n\")\n",
        "result_docs = set(inverted_index.get(query[0], []))\n",
        "for term in query[1:]:\n",
        "    result_docs = result_docs.intersection(inverted_index.get(term, []))\n",
        "if result_docs:\n",
        "    print(\"Retrieved Documents:\", result_docs)\n",
        "else:\n",
        "    print(\"No document contains all query terms.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_UX-7FaAIZc",
        "outputId": "d32c11fe-542f-456a-d168-ecfd0b1850a6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T114 | Bhumika Shelar\n",
            "\n",
            "Documents containing the terms 'tycs journal':\n",
            "\n",
            "Retrieved Documents: {'Document 2'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 5**\n",
        "\n",
        "Implement an inverted index construction algorithm for the following two documents\n",
        "\n",
        "document1 = \"our class meeting starts soon\"\n",
        "\n",
        "document2 = \"my class starts at 6.\"\n",
        "\n",
        "Build a simple document retrieval system using the constructed index to\n",
        "find the documents containing terms “class meeting”."
      ],
      "metadata": {
        "id": "CIKL43IhAIpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"T114 | Bhumika Shelar\")\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "document1 = \"our class meeting starts soon\"\n",
        "document2 = \"my class starts at 6.\"\n",
        "nltk.download('stopwords')\n",
        "stopWords = stopwords.words('english')\n",
        "\n",
        "tokens1 = document1.lower().split()\n",
        "tokens2 = document2.lower().split()\n",
        "\n",
        "terms = list(set(tokens1 + tokens2))\n",
        "inverted_index = {}\n",
        "occ_num_doc1 = {}\n",
        "occ_num_doc2 = {}\n",
        "for term in terms:\n",
        "    if term in stopWords:\n",
        "        continue  # ignore stopwords\n",
        "    documents = []\n",
        "    if term in tokens1:\n",
        "        documents.append(\"Document 1\")\n",
        "        occ_num_doc1[term] = tokens1.count(term)\n",
        "    if term in tokens2:\n",
        "        documents.append(\"Document 2\")\n",
        "        occ_num_doc2[term] = tokens2.count(term)\n",
        "\n",
        "    inverted_index[term] = documents\n",
        "query = [\"tycs\", \"journal\"]   # query terms\n",
        "print(\"\\nDocuments containing the terms 'tycs journal':\\n\")\n",
        "result_docs = set(inverted_index.get(query[0], []))\n",
        "for term in query[1:]:\n",
        "    result_docs = result_docs.intersection(inverted_index.get(term, []))\n",
        "if result_docs:\n",
        "    print(\"Retrieved Documents:\", result_docs)\n",
        "else:\n",
        "    print(\"No document contains all query terms.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH2pexWSALJl",
        "outputId": "296f7d70-96c3-4ce4-8915-215a42406936"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T114 | Bhumika Shelar\n",
            "\n",
            "Documents containing the terms 'tycs journal':\n",
            "\n",
            "No document contains all query terms.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}